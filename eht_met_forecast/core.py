import datetime
import os.path
import subprocess
import math
import requests
import sys
import time
import io
import contextlib
import tempfile
from argparse import ArgumentParser
import json

import pygrib

from .timer_utils import record_latency, dump_latency_histograms

sites = [
    {'name': 'sma', 'desc': 'the SMA', 'lat': 19.824, 'lon': -155.478, 'alt': 4080},
]


expected_lines = 210
appdir = '.'
header_amc = '''
#
# This header is prepended to the atmospheric layers generated by
# gfs15_to_am10.py to generate a complete am configuration file.
#
f 225 GHz 225 GHz 1 GHz
output f GHz tau Tb K
T0 2.7 K
'''
am_executable = '/usr/local/bin/am'

GFS_TIMESTAMP = '%Y%m%d_%H:00:00'
GFS_DAYHOUR = '%Y%m%d/%H'
GFS_DAY = '%Y%m%d'
GFS_HOUR = '%H'
table_header = ('#', 'date', 'tau255', 'Tb[K]', 'pwv[mm]', 'lwp[kg*m^-2]', 'iwp[kg*m^-2]', 'o3[DU]')

LAYER_HEADER = """
#
# Layer data below were derived from NCEP GFS model data obtained
# from the NOAA Operational Model Archive Distribution System
# (NOMADS).  See http://nomads.ncep.noaa.gov for more information.
#
#         Production date: {0}
#                   Cycle: {1:02d} UT
#                 Product: {2}
#
# Interpolated to
#
#                latitude: {3} deg. N
#               longitude: {4} deg. E
#   Geopotential altitude: {5} m
#
"""


def latest_gfs_cycle_time(now=None):
    if now is None:
        now = datetime.datetime.utcnow()
    else:
        now = datetime.datetime.fromtimestamp(now)

    gfs_lag = 5.2  # hours
    dt_gfs_lag = datetime.timedelta(hours=gfs_lag)
    dt_gfs     = now - dt_gfs_lag
    dt_gfs     = dt_gfs.replace(hour=int(dt_gfs.hour / 6) * 6, minute=0, second=0, microsecond=0)
    return dt_gfs


def ok(outfile, verbose=False):
    if not os.path.exists(outfile):
        if verbose:
            print(outfile, 'does not exist', file=sys.stderr)
        return False
    with open(outfile) as f:
        count = len(f.readlines())
        if count != expected_lines:
            print(outfile, 'saw', count, 'lines, not good')
            return False
    if verbose:
        print(outfile, 'exists and has the correct count')
    return True


table_line_string = '{:1s}{:>16s} {:>12s} {:>12s} {:>12s} {:>12s} {:>12s} {:>12s}'
table_line_floats = '{} {:12.4e} {:12.4e} {:12.4e} {:12.4e} {:12.4e} {:12.4e}'


def print_table_line(fields, f):
    print(table_line_string.format(*fields), file=f)


LATLON_GRID_STR = "0p25"
LEVELS = (1, 2, 3, 5, 7, 10, 20, 30, 50, 70, 100, 150, 200, 250, 300, 350, 400,
          450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 925, 950, 975, 1000)


def form_gfs_download_url(lat, lon, alt, gfs_cycle, forecast_hour):
    CGI_URL = "https://nomads.ncep.noaa.gov/cgi-bin/filter_gfs_{}_1hr.pl"
    url = CGI_URL.format(LATLON_GRID_STR)

    latlon_delta = float(LATLON_GRID_STR[0:1]) + 0.01 * float(LATLON_GRID_STR[2:])  # 0p25 -> 0.25
    leftlon = math.floor(lon / latlon_delta) * latlon_delta
    rightlon = leftlon + latlon_delta
    bottomlat = math.floor(lat / latlon_delta) * latlon_delta
    toplat = bottomlat + latlon_delta

    gfs_dayhour = gfs_cycle.strftime(GFS_DAYHOUR)
    gfs_hour = gfs_cycle.strftime(GFS_HOUR)
    gfs_product = 'f{:03d}'.format(forecast_hour)

    params = {
        'dir': '/gfs.{}'.format(gfs_dayhour),
        'file': 'gfs.t{}z.pgrb2.{}.{}'.format(gfs_hour, LATLON_GRID_STR, gfs_product),
        'subregion': '',
        'leftlon': leftlon,
        'rightlon': rightlon,
        'toplat': toplat,
        'bottomlat': bottomlat,
    }

    LEVELS = (1, 2, 3, 5, 7, 10, 20, 30, 50, 70, 100, 150, 200, 250, 300, 350, 400,
              450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 925, 950, 975, 1000)
    for lev in LEVELS:
        params['lev_{:d}_mb'.format(lev)] = 'on'
    VARIABLES = ("CLWMR", "ICMR", "HGT", "O3MR", "RH", "TMP")
    for var in VARIABLES:
        params['var_' + var] = 'on'

    return url, params


def fetch_gfs_download(url, params):
    # Timeouts and retries
    CONN_TIMEOUT        = 4        # Initial server response timeout in seconds
    READ_TIMEOUT        = 4        # Stalled download timeout in seconds
    RETRY_DELAY         = 60       # Delay before retry (NOAA requests 60 s)
    MAX_DOWNLOAD_TRIES  = 4

    retry = MAX_DOWNLOAD_TRIES
    while retry > 0:
        try:
            r = requests.get(url, params=params, timeout=(CONN_TIMEOUT, READ_TIMEOUT))
            if r.status_code == requests.codes.ok:
                errflag = 0
            else:
                errflag = 1
                print('url was', r.url, file=sys.stderr)
                print("Download failed with status code {0}".format(r.status_code),
                      file=sys.stderr, end='')
                print('content is', r.content, file=sys.stderr)
        except requests.exceptions.ConnectTimeout:
            print("Connection timed out.", file=sys.stderr, end='')
            errflag = 1
        except requests.exceptions.ReadTimeout:
            print("Data download timed out.", file=sys.stderr, end='')
            errflag = 1
        if (errflag):
            retry = retry - 1
            if (retry):
                print("  Retrying...", file=sys.stderr)
                time.sleep(RETRY_DELAY)
            else:
                print("  Giving up.", file=sys.stderr)
                print("Failed URL was: ", file=sys.stderr)
                print(url, file=sys.stderr)
                exit(1)
        else:
            break

    return r.content


def download_gfs(lat, lon, alt, gfs_cycle, forecast_hour):
    url, params = form_gfs_download_url(lat, lon, alt, gfs_cycle, forecast_hour)
    grib_buffer = fetch_gfs_download(url, params)
    return grib_buffer


def grid_interp(a, u, v):
    return (a[0][0] * (1.0 - u) * (1.0 - v) + a[1][0] * u * (1.0 - v)
          + a[0][1] * (1.0 - u) * v         + a[1][1] * u * v       )


# Numerical and physical constants
BADVAL              = -99999.  # placeholder for missing or undefined data
BADVAL_TEST         = -99998.
G_STD               = 9.80665  # standard gravity [m / s^2]
M_AIR               = 28.964   # average dry air mass [g / mole]
M_O3                = 47.997   # O3 mass [g / mole]
H2O_SUPERCOOL_LIMIT = 238.     # Assume ice below this temperature [K]
PASCAL_ON_MBAR      = 100.     # conversion from mbar (hPa) to Pa

RH_TOP_PLEVEL = 29.
STRAT_H2O_VMR = 5e-6


def grib2_to_am_layers(gribname, lat, lon, alt):
    grbindx = pygrib.index(gribname, "name", "level")

    # in memory -- not sure what syntax actually works for this?
    # need to .index() after creation
    # gribfile = pygrib.fromstring(grib_buffer)
    # gribindx = ???

    latlon_delta = float(LATLON_GRID_STR[0:1]) + 0.01 * float(LATLON_GRID_STR[2:])
    leftlon = math.floor(lon / latlon_delta) * latlon_delta
    bottomlat = math.floor(lat / latlon_delta) * latlon_delta

    u = (lat - bottomlat) / latlon_delta
    v = (lon - leftlon) / latlon_delta
    Pbase     = []
    z         = []
    T         = []
    o3_vmr    = []
    RH        = []
    cloud_lmr = []
    cloud_imr = []

    for i, lev in enumerate(LEVELS):
        Pbase.append(lev)
        try:
            x = (grid_interp(grbindx.select(
                name="Geopotential Height", level=lev)[0].values, u, v))
            z.append(x)
        except:
            z.append(BADVAL)
        try:
            x = (grid_interp(grbindx.select(
                name="Temperature", level=lev)[0].values, u, v))
            T.append(x)
        except:
            T.append(BADVAL)
        try:
            x = (grid_interp(grbindx.select(
                name="Ozone mixing ratio", level=lev)[0].values, u, v))
            x *= M_AIR / M_O3  # convert mass mixing ratio to volume mixing ratio
            o3_vmr.append(x)
        except:
            o3_vmr.append(0.0)
        try:
            x = (grid_interp(grbindx.select(
                name="Relative humidity", level=lev)[0].values, u, v))
            if (lev >= RH_TOP_PLEVEL):
                RH.append(x)
            else:
                RH.append(0.0)
        except:
            RH.append(0.0)
        try:
            x = (grid_interp(grbindx.select(
                name="Cloud mixing ratio", level=lev)[0].values, u, v))
            cloud_lmr.append(x)
        except:
            cloud_lmr.append(0.0)
        try:
            x = (grid_interp(grbindx.select(
                name="Ice water mixing ratio", level=lev)[0].values, u, v))
            cloud_imr.append(x)
        except:
            cloud_imr.append(0.0)

    return Pbase, z, T, o3_vmr, RH, cloud_lmr, cloud_imr


def print_am_header(gfs_cycle, forecast_hour, lat, lon, alt):
    gfs_day = gfs_cycle.strftime(GFS_DAY)
    gfs_hour = gfs_cycle.hour
    gfs_product = 'f{:03d}'.format(forecast_hour)
    if (gfs_product == "anl"):
        product_str = "analysis"
    else:
        product_str = gfs_product[1:] + " hour forecast"
    print(LAYER_HEADER.format(gfs_day, gfs_hour, product_str, lat, lon, alt))


def print_am_layers(alt, Pbase, z, T, o3_vmr, RH, cloud_lmr, cloud_imr):
    for i, lev in enumerate(LEVELS):
        if (z[i] < alt):
            break
        print("layer")
        print("Pbase {0:.1f} mbar  # {1:.1f} m".format(Pbase[i], z[i]))
        print("Tbase {0:.1f} K".format(T[i]))
        print("column dry_air vmr")
        if (i > 0):
            o3_vmr_mid    = 0.5 * (   o3_vmr[i-1] +    o3_vmr[i])
            RH_mid        = 0.5 * (       RH[i-1] +        RH[i])
            cloud_lmr_mid = 0.5 * (cloud_lmr[i-1] + cloud_lmr[i])
            cloud_imr_mid = 0.5 * (cloud_imr[i-1] + cloud_imr[i])
            T_mid         = 0.5 * (        T[i-1] +         T[i])
        else:
            o3_vmr_mid    = o3_vmr[i]
            RH_mid        = RH[i]
            cloud_lmr_mid = cloud_lmr[i]
            cloud_imr_mid = cloud_imr[i]
            T_mid         = T[i]
        if (o3_vmr_mid > 0.0):
            print("column o3 vmr {0:.3e}".format(o3_vmr_mid))
        if (RH_mid > 0.0):
            if (T_mid > H2O_SUPERCOOL_LIMIT):
                print("column h2o RH {0:.2f}%".format(RH_mid))
            else:
                print("column h2o RHi {0:.2f}%".format(RH_mid))
        if (cloud_lmr_mid > 0.0):
            #
            # Convert cloud liquid water mixing ratio [kg / kg] to
            # cloud total liquid water across the layer [kg / m^2].
            # Below the supercooling limit, assume any liquid water
            # is really ice.  (GFS 15 occasionally has numerically
            # negligible amounts of liquid water at unphysically
            # low temperature.)
            #
            dP = PASCAL_ON_MBAR * (Pbase[i] - Pbase[i-1])
            m = dP / G_STD
            ctw = m * cloud_lmr_mid
            if (T_mid < H2O_SUPERCOOL_LIMIT):
                print("column iwp_abs_Rayleigh {0:.3e} kg*m^-2".format(ctw))
            else:
                print("column lwp_abs_Rayleigh {0:.3e} kg*m^-2".format(ctw))
        if (cloud_imr_mid > 0.0):
            #
            # Convert cloud ice mixing ratio [kg / kg] to cloud total
            # ice across the layer [kg / m^2].
            #
            dP = PASCAL_ON_MBAR * (Pbase[i] - Pbase[i-1])
            m = dP / G_STD
            cti = m * cloud_imr_mid
            print("column iwp_abs_Rayleigh {0:.3e} kg*m^-2".format(cti))
        print("")

    if (z[i] == alt):
        return

    u = (alt - z[i-1]) / (z[i] - z[i-1])
    logP_s = u * math.log(Pbase[i]) + (1.0 - u) * math.log(Pbase[i-1]) 
    P_s = math.exp(logP_s)
    T_s = u * T[i] + (1.0 - u) * T[i-1]

    #
    # Other variables are interpolated or extrapolated linearly in P
    # to the base level and clamped at zero.
    #
    u = (P_s - Pbase[i-1]) / (Pbase[i] - Pbase[i-1])
    o3_vmr_s    =   u * o3_vmr[i]  + (1.0 - u) *    o3_vmr[i-1]
    RH_s        =       u * RH[i]  + (1.0 - u) *        RH[i-1]
    cloud_lmr_s = u * cloud_lmr[i] + (1.0 - u) * cloud_lmr[i-1]
    cloud_imr_s = u * cloud_imr[i] + (1.0 - u) * cloud_imr[i-1]
    if (o3_vmr_s < 0.0):
        o3_vmr_s = 0.0
    if (RH_s < 0.0):
        RH_s = 0.0
    if (cloud_lmr_s < 0.0):
        cloud_lmr_s = 0.0
    if (cloud_imr_s < 0.0):
        cloud_imr_s = 0.0
    o3_vmr_mid    = 0.5 * (   o3_vmr[i-1] +    o3_vmr_s)
    RH_mid        = 0.5 * (       RH[i-1] +        RH_s)
    cloud_lmr_mid = 0.5 * (cloud_lmr[i-1] + cloud_lmr_s)
    cloud_imr_mid = 0.5 * (cloud_imr[i-1] + cloud_imr_s)
    print("layer")
    print("Pbase {0:.1f} mbar  # {1:.1f} m".format(P_s, alt))
    print("Tbase {0:.1f} K".format(T_s))
    print("column dry_air vmr")
    if (o3_vmr_mid > 0.0):
        print("column o3 vmr {0:.3e}".format(o3_vmr_mid))
    if (RH_mid > 0.0):
        if (T_mid > H2O_SUPERCOOL_LIMIT):
            print("column h2o RH {0:.2f}%".format(RH_mid))
        else:
            print("column h2o RHi {0:.2f}%".format(RH_mid))
    if (cloud_lmr_mid > 0.0):
        dP = PASCAL_ON_MBAR * (Pbase[i] - Pbase[i-1])
        m = dP / G_STD
        ctw = m * cloud_lmr_mid
        print("column lwp_abs_Rayleigh {0:.3e} kg*m^-2".format(ctw))
    if (cloud_imr_mid > 0.0):
        dP = PASCAL_ON_MBAR * (Pbase[i] - Pbase[i-1])
        m = dP / G_STD
        cti = m * cloud_imr_mid
        print("column iwp_abs_Rayleigh {0:.3e} kg*m^-2".format(cti))


def gfs15_to_am10(lat, lon, alt, gfs_cycle, forecast_hour):
    grib_buffer = download_gfs(lat, lon, alt, gfs_cycle, forecast_hour)

    grib_problem = False
    with tempfile.NamedTemporaryFile(mode='wb', prefix='temp-', suffix='.grb') as f:
        f.write(grib_buffer)
        f.flush()
        try:
            Pbase, z, T, o3_vmr, RH, cloud_lmr, cloud_imr = grib2_to_am_layers(f.name, lat, lon, alt)
        except Exception as e:
            # example: RuntimeError: b'End of resource reached when reading message'
            # example: UserWarning: file temp.grb has multi-field messages, keys inside multi-field messages will not be indexed correctly
            grib_problem = str(e)

    if not grib_problem:
        my_stdout = io.StringIO()
        with contextlib.redirect_stdout(my_stdout):
            try:
                print_am_header(gfs_cycle, forecast_hour, lat, lon, alt)
                print_am_layers(alt, Pbase, z, T, o3_vmr, RH, cloud_lmr, cloud_imr)
            except Exception as e:
                # example: ZeroDivisionError after a bunch of
                #   ECCODES INFO    :  grib_file_open: cannot open file foo.grb (No such file or directory)
                grib_problem = str(e)

    if grib_problem:
        with tempfile.NamedTemporaryFile(mode='w', prefix='layers-err-', suffix='.grb', dir='.', delete=False) as tfile:
            print('some problem turning the grib into layers, saving ', tfile.name, file=sys.stderr)
            tfile.write(grib_buffer)
            tfile.flush()
            fname = tfile.name[:-4]+'.info'
            with open(fname, 'w') as f:
                print(grib_problem, file=f)
                print('lat', lat, 'lon', lon, 'alt', alt, 'gfs_cycle', gfs_cycle, 'forecast_hour', forecast_hour, file=f)
        return

    return my_stdout.getvalue()


def run_am(layers_amc):
    stdin = header_amc.encode() + layers_amc.encode()

    args = (am_executable, '-')

    completed = subprocess.run(args, input=stdin, capture_output=True)
    returncode = completed.returncode
    stdout = completed.stdout.decode()  # one line with the integrated opacity
    stderr = completed.stderr.decode()  # verbose stuff

    return returncode, stdout, stderr


def summarize_am(am_output, am_error):
    lwp = 0.
    iwp = 0.
    for line in am_error.splitlines():
        if line.startswith('#'):
            if 'h2o' in line:
                pwv = float(line.split()[2])
            if 'lwp_abs_Rayleigh' in line:
                lwp = float(line.split()[2])
            if 'iwp_abs_Rayleigh' in line:
                iwp = float(line.split()[2])
            if 'o3' in line:
                o3 = float(line.split()[2])

    parts = am_output.split()
    tau = float(parts[1])
    Tb = float(parts[2])

    MM_PWV   = 3.3427e21
    KG_ON_M2 = 3.3427e21
    DU       = 2.6868e16

    return tau, Tb, pwv / MM_PWV, lwp / KG_ON_M2, iwp / KG_ON_M2, o3 / DU


def print_final_output(gfs_timestamp, tau, Tb, pwv, lwp, iwp, o3, f):
    out = table_line_floats.format(gfs_timestamp, tau, Tb, pwv, lwp, iwp, o3)
    print(out, file=f)
    f.flush()
    print(out, file=sys.stderr)


def compute_one_hour(site, gfs_cycle, forecast_hour, f):
    print('fetching for hour', forecast_hour, file=sys.stderr)
    with record_latency('fetch gfs data'):
        layers_amc = gfs15_to_am10(site['lat'], site['lon'], site['alt'], gfs_cycle, forecast_hour)
    if layers_amc is None:
        return  # no line emitted

    dt_forecast_hour = gfs_cycle + datetime.timedelta(hours=forecast_hour)
    am_problem = False
    with record_latency('run am'):
        returncode, am_output, am_error = run_am(layers_amc)
    if returncode not in (0, 1):
        # am exits 1 for warnings: '! Warning: Water ice was encountered on a layer where models were'
        am_problem = 'saw returncode of {}'.format(returncode)

    if not am_problem:
        try:
            tau, Tb, pwv, lwp, iwp, o3 = summarize_am(am_output, am_error)
        except Exception as e:
            am_problem = str(e)

    if am_problem:
        with tempfile.NamedTemporaryFile(mode='w', prefix='am-problem-', dir='.', delete=False) as tfile:
            print('problem running am, saving input and output to', tfile.name, file=sys.stderr)
            # example: -(35) : The volume mixing ratio must be in the range 0 to 1.
            # ! Error: parse error.
            tfile.write('am_problem: {}\n'.format(am_problem))
            tfile.write('Input:\n\n')
            tfile.write(header_amc)
            tfile.write(layers_amc)
            tfile.write('\nOutput:\n\n')
            tfile.write(am_error)
            tfile.write(am_output)
            return  # no line emitted

    print_final_output(dt_forecast_hour.strftime(GFS_TIMESTAMP), tau, Tb, pwv, lwp, iwp, o3, f)
    dump_latency_histograms()
    time.sleep(1)


def make_forecast_table(site, gfs_cycle, f):
    print_table_line(table_header, f)
    for forecast_hour in range(0, 121):
        compute_one_hour(site, gfs_cycle, forecast_hour, f)
    for forecast_hour in range(123, 385, 3):
        compute_one_hour(site, gfs_cycle, forecast_hour, f)


def read_stations(filename):
    if filename is None:
        filename = os.path.split(__file__)[0] + '/data/stations.json'
    with open(filename, 'r') as f:
        return json.load(f)


def interpret_args(args, station_dict):
    print_vexes = False
    if not args.vex:
        stations = station_dict.keys()
    else:
        stations = []
        for vex in args.vex:
            if ',' in vex:
                vexes = vex.split(',')
            else:
                vexes = (vex,)
            for v in vexes:
                if v in station_dict:
                    stations.append(v)
                else:
                    print('unknown vex', v, file=sys.stderr)
                    print_vexes = True
    if print_vexes:
        print('valid vexes are:', file=sys.stderr)
        for k, v in station_dict.items():
            print(' ', k, v['name'], file=sys.stderr)

    cycles = []
    if args.cycle:
        c = args.cycle
        if len(c) not in (8, 10):
            raise ValueError('unknown cycle time format, expecting YYYYMMDDHH: '+args.cycle)
        if len(c) == 8:
            c += '00'
        gfs_starting_cycle = datetime.datetime.strptime(c, '%Y%m%d%H')
    else:
        gfs_starting_cycle = latest_gfs_cycle_time()

    end_hours = 1
    if args.backfill:
        end_hours = args.backfill + 1
    for hours_ago in range(0, end_hours, 6):
        dt_gfs_lag = datetime.timedelta(hours=-hours_ago)
        gfs_cycle = (gfs_starting_cycle + dt_gfs_lag)
        cycles.append(gfs_cycle)

    return stations, cycles


def main(args=None):
    parser = ArgumentParser(description='eht-met-forecast command line tool')
    parser.add_argument('--vex', action='append', help='station(s) to fetch')
    parser.add_argument('--stations', action='store', help='station configuration file (default: builtin list)')
    parser.add_argument('--backfill', action='store', default=0, type=int, help='hours to backfill')
    parser.add_argument('--cycle', action='store', help='gfs cycle to fetch (e.g. 2020031200)')
    parser.add_argument('--dir', action='store', default='eht-met-forecast-output',
                        help='directory to store output (default: eht-met-forecast-output')
    parser.add_argument('--dry-run', '-n', action='store_true', help='Show what would be done. Implies -v')
    parser.add_argument('--verbose', '-v', action='store_true', help='Print more information')
    args = parser.parse_args(args=args)

    verbose = args.verbose
    if args.dry_run:
        verbose = True

    station_locations = read_stations(args.stations)
    station_dict = dict([(v['vex'], v) for v in station_locations])

    stations, cycles = interpret_args(args, station_dict)

    for vex in stations:
        station = station_dict[vex]
        for gfs_cycle in cycles:
            print('processing station', vex, 'cycle', gfs_cycle.strftime(GFS_TIMESTAMP), file=sys.stderr)
            outdir = '{}/{}'.format(args.dir, vex)
            outfile = '{}/{}'.format(outdir, gfs_cycle.strftime(GFS_TIMESTAMP))
            if ok(outfile, verbose=verbose):
                if verbose:
                    print('outfile {} seems ok, not re-fetching'.format(outfile), file=sys.stderr)
                continue
            if verbose or args.dry_run:
                print('processing', outfile, file=sys.stderr)
                if args.dry_run:
                    continue
            os.makedirs(outdir, exist_ok=True)
            with open(outfile, 'w') as f:
                make_forecast_table(station, gfs_cycle, f)
    else:
        print('no valid stations to fetch', file=sys.stderr)
        exit(1)


if __name__ == '__main__':
    main()
